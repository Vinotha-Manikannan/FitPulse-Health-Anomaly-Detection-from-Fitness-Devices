{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEIZ_Av7qywL",
        "outputId": "817992e7-f88d-4961-9c0b-dc8fa6555d19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.52.2)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.5.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.4)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2.13.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.30.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2026-01-11T06:09:29+0000 lvl=warn msg=\"failed to open private leg\" id=ba96e318d528 privaddr=localhost:8501 err=\"dial tcp [::1]:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2026-01-11T06:09:29+0000 lvl=warn msg=\"failed to open private leg\" id=7e879cdb9289 privaddr=localhost:8501 err=\"dial tcp [::1]:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2026-01-11T06:09:32+0000 lvl=warn msg=\"failed to open private leg\" id=dd2ca68aa697 privaddr=localhost:8501 err=\"dial tcp [::1]:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2026-01-11T06:09:32+0000 lvl=warn msg=\"failed to open private leg\" id=c457b72d210c privaddr=localhost:8501 err=\"dial tcp [::1]:8501: connect: connection refused\"\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit pyngrok pandas numpy plotly scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "st.set_page_config(page_title=\"Health Anomaly Dashboard\", layout=\"wide\")\n",
        "st.title(\" Health Anomaly Detection Dashboard\")\n",
        "st.markdown(\"Upload fitness data (CSV/JSON) to detect anomalies and view insights interactively.\")\n",
        "\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload CSV or JSON file\", type=[\"csv\", \"json\"])\n",
        "\n",
        "\n",
        "def preprocess_fitness_data(df):\n",
        "    \"\"\"Clean dataframe: standardize column names and timestamps.\"\"\"\n",
        "    df = df.copy()\n",
        "    df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
        "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\", dayfirst=True)\n",
        "    df = df.dropna(subset=[\"timestamp\"])\n",
        "    df = df.sort_values(\"timestamp\")\n",
        "    return df\n",
        "\n",
        "def detect_anomalies(df, metric):\n",
        "    \"\"\"Detect anomalies using IsolationForest with scaling.\"\"\"\n",
        "    if df.empty:\n",
        "        st.error(\"No valid timestamp data found after preprocessing.\")\n",
        "        st.stop()\n",
        "\n",
        "    if df.shape[0] < 3:\n",
        "        df[metric + \"_anomaly\"] = \"Normal\"\n",
        "        return df\n",
        "\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(df[[metric]].fillna(df[metric].median()))\n",
        "\n",
        "\n",
        "    model = IsolationForest(contamination=0.05, random_state=42)\n",
        "    df[metric + \"_anomaly\"] = model.fit_predict(X_scaled)\n",
        "    df[metric + \"_anomaly\"] = df[metric + \"_anomaly\"].map({1: \"Normal\", -1: \"Anomaly\"})\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "if uploaded_file:\n",
        "\n",
        "    if uploaded_file.name.endswith(\".csv\"):\n",
        "        df_raw = pd.read_csv(uploaded_file)\n",
        "    else:\n",
        "        df_raw = pd.read_json(uploaded_file)\n",
        "\n",
        "    st.subheader(\" Raw Data Preview\")\n",
        "    st.dataframe(df_raw.head(10))\n",
        "\n",
        "    df = preprocess_fitness_data(df_raw)\n",
        "    numeric_metrics = df.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "    if not numeric_metrics:\n",
        "        st.error(\" No numeric columns found for analysis.\")\n",
        "        st.stop()\n",
        "\n",
        "\n",
        "    st.sidebar.header(\"⚙️ Controls\")\n",
        "    metric = st.sidebar.selectbox(\"Select Metric for Plotting\", numeric_metrics)\n",
        "\n",
        "\n",
        "    min_date = df[\"timestamp\"].min()\n",
        "    max_date = df[\"timestamp\"].max()\n",
        "    date_range = st.sidebar.date_input(\"Select Date Range\", [min_date.date(), max_date.date()])\n",
        "    start_date, end_date = pd.to_datetime(date_range[0]), pd.to_datetime(date_range[1])\n",
        "    df_filtered = df[(df[\"timestamp\"] >= start_date) & (df[\"timestamp\"] <= end_date)]\n",
        "\n",
        "    if df_filtered.empty:\n",
        "        st.warning(\" No data in selected date range.\")\n",
        "    else:\n",
        "\n",
        "        for m in numeric_metrics:\n",
        "            df_filtered = detect_anomalies(df_filtered, m)\n",
        "\n",
        "        st.subheader(\"Summary Statistics for All Metrics\")\n",
        "        summary_list = []\n",
        "        for m in numeric_metrics:\n",
        "            total = len(df_filtered)\n",
        "            anomalies = (df_filtered[m + \"_anomaly\"] == \"Anomaly\").sum()\n",
        "            summary_list.append({\n",
        "                \"Metric\": m,\n",
        "                \"Mean\": round(df_filtered[m].mean(), 2),\n",
        "                \"Median\": round(df_filtered[m].median(), 2),\n",
        "                \"Anomaly Count\": anomalies,\n",
        "                \"Anomaly %\": round(anomalies / total * 100, 2)\n",
        "            })\n",
        "        summary_df = pd.DataFrame(summary_list)\n",
        "        st.table(summary_df)\n",
        "\n",
        "        st.subheader(f\" {metric.replace('_',' ').title()} Trend with Anomalies\")\n",
        "        fig = px.line(\n",
        "            df_filtered,\n",
        "            x=\"timestamp\",\n",
        "            y=metric,\n",
        "            color=metric + \"_anomaly\",\n",
        "            markers=True,\n",
        "            title=f\"{metric.replace('_',' ').title()} with Anomalies\"\n",
        "        )\n",
        "        st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "        st.subheader(f\"Detected Anomalies for {metric}\")\n",
        "        st.dataframe(df_filtered[df_filtered[metric + \"_anomaly\"] == \"Anomaly\"])\n",
        "\n",
        "        csv = df_filtered.to_csv(index=False).encode(\"utf-8\")\n",
        "        st.download_button(\n",
        "            \"⬇️ Download Result CSV\",\n",
        "            csv,\n",
        "            \"anomaly_output.csv\",\n",
        "            \"text/csv\"\n",
        "        )\n",
        "\n",
        "else:\n",
        "    st.info(\"⬆️ Please upload a CSV or JSON file to continue.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb2rCk07q2Fo",
        "outputId": "f8bbb08d-2e10-41ae-aa1e-45382d24e7d3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.set_auth_token(\"36byQbgfeXjiJqt5Dk7WpO9fzoy_4NTSEZSZz44vXtK6Zk2oC\")\n"
      ],
      "metadata": {
        "id": "PYQ8tvajq4R5"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup streamlit run app.py &>/dev/null &\n"
      ],
      "metadata": {
        "id": "7iUR549dq48Y"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "public_url = ngrok.connect(8501)\n",
        "public_url\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omKU8YOoq6-5",
        "outputId": "65bc1f60-cb1c-466f-b632-b6b908c4ab24"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"https://giancarlo-dedicatory-mauricio.ngrok-free.dev\" -> \"http://localhost:8501\">"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "vNWi28RHw9oa"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}